{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annettteee/Data/blob/main/Annette_Movie_Recommendation_System_NSDC_Data_Science_Projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTUk7S0GxzNv"
      },
      "source": [
        "<h1 align=\"center\">\n",
        "    NSDC Data Science Projects\n",
        "</h1>\n",
        "  \n",
        "<h2 align=\"center\">\n",
        "    Project: Movie Recommendation System\n",
        "</h2>\n",
        "\n",
        "<h3 align=\"center\">\n",
        "    Name: (Annette)\n",
        "</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duXjuu5Ax1-z"
      },
      "source": [
        "### **Please read before you begin your project**\n",
        "\n",
        "**Instructions: Google Colab Notebooks:**\n",
        "\n",
        "Google Colab is a free cloud service. It is a hosted Jupyter notebook service that requires no setup to use, while providing free access to computing resources. We will be using Google Colab for this project.\n",
        "\n",
        "Certain parts of this project will be completed individually, while other parts are encouraged to be completed with the rest of your team. In order to work within the Google Colab Notebook, **please start by clicking on \"File\" and then \"Save a copy in Drive.\"** This will save a copy of the notebook in your personal Google Drive. Each member of your team should work on their personal copy.\n",
        "\n",
        "Please rename the file to \"Movie Recommendation Analysis - Your Full Name.\" Once this project is completed, you will be prompted to share your file with the National Student Data Corps (NSDC) Project Leaders.\n",
        "\n",
        "You can now start working on the project. :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHba4I24yBt8"
      },
      "source": [
        "We'll be using Google Colab for this assignment. This is a Python Notebook environment built by Google that's free for everyone and comes with a nice UI out of the box. For a comprehensive guide, see Colab's official guide [here](https://colab.research.google.com/github/prites18/NoteNote/blob/master/Welcome_To_Colaboratory.ipynb).\n",
        "\n",
        "Colab QuickStart:\n",
        "- Notebooks are made up of cells, cells can be either text or code cells. Click the +code or +text button at the top to create a new cell\n",
        "- Text cells use a format called [Markdown](https://www.markdownguide.org/getting-started/). Cheatsheet is available [here](https://www.markdownguide.org/cheat-sheet/)\n",
        "- Python code is run/executed in code cells. You can click the play button at the top left of a code block (sometimes hidden in the square brackets) to run the code in that cell. You an also hit shift+enter to run the cell that is currently selected. There is no concurrency since cells run one at a time but you can queue up multiple cells\n",
        "- Each cell will run code individually but memory is shared across a notebook Runtime. You can think of a Runtime as a code session where everything you create and execute is temporarily stored. This means variables and functions are available between cells if you execute one cell before the other (physical ordering of cells does not matter). This also means that if you delete or change the name of something and re-execute the cell, the old data might still exist in the background. If things aren't making sense, you can always click Runtime -> restart runtime to start over.\n",
        "- Runtimes will persist for a short period of time so you are safe if you lose connection or refresh the page but Google will shutdown a runtime after enough time has past. Everything that was printed out will remain on the page even if the runtime is disconnected\n",
        "- Google's Runtimes come preinstalled with all the core python libraries (math, rand, time, etc) as well as common data analysis libraries (numpy, pandas, scikitlearn, matplotlib). Simply run `import numpy as np` in a code cell to make it available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81bBnH8IyJIQ"
      },
      "source": [
        "# **Singular Value Decomposition**\n",
        "\n",
        "---\n",
        "\n",
        "# Crash Course on Singular Value Decomposition (SVD)\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Singular Value Decomposition, or SVD, is a mathematical technique used in many fields such as signal processing, statistics, and machine learning, particularly in the context of recommendation systems. It's a method for decomposing a matrix into three other matrices that reveal its underlying structure.\n",
        "\n",
        "## Basic Concepts\n",
        "\n",
        "### Matrices\n",
        "- **Matrix**: A rectangular array of numbers.\n",
        "- **Dimension of a Matrix**: Given in the form of rows × columns.\n",
        "\n",
        "### Decomposition\n",
        "- **Decomposition**: Breaking down a complex matrix into simpler, understandable parts.\n",
        "\n",
        "## What is SVD?\n",
        "\n",
        "```\n",
        "SVD breaks down any given matrix A into three separate matrices named U, Σ and V*\n",
        "ie. A = UΣV*\n",
        "```\n",
        "Where the components are:\n",
        "```\n",
        "- A: Original matrix.\n",
        "- U: Left singular vectors (orthogonal matrix).\n",
        "- Σ: Diagonal matrix of singular values (non-negative).\n",
        "- V*: Right singular vectors (conjugate transpose of V , an orthogonal matrix).\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLwYe8rLJY_-"
      },
      "source": [
        "## Where do we use SVDs?\n",
        "\n",
        "### Applications in Recommendation Systems\n",
        "\n",
        "In recommendation systems, SVD is used to predict unknown preferences by decomposing a large matrix of user-item interactions into factors representing latent features. It helps in capturing the underlying patterns in the data.\n",
        "\n",
        "### Process\n",
        "\n",
        "1. **Matrix Creation**: Start with a matrix where rows represent users, columns represent items, and entries represent user ratings.\n",
        "2. **Apply SVD**: Decompose this matrix using SVD.\n",
        "3. **Latent Features**: The decomposition reveals latent features that explain observed ratings.\n",
        "4. **Prediction**: Use the decomposed matrices to predict missing ratings.\n",
        "\n",
        "### Advantages of an SVD\n",
        "- Effective at uncovering latent features in the data.\n",
        "- Reduces dimensionality, making computations more manageable.\n",
        "\n",
        "### Limitations of an SVD\n",
        "- Assumes linear relationships in data.\n",
        "- Sensitive to missing data and outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_2UqcW9JmGT"
      },
      "source": [
        "#### Through this project, we will learn how to build a movie recommendation system using an SVD\n",
        "\n",
        "\n",
        "#### Dataset being used : **Movielens 100k dataset**\n",
        "\n",
        "- This specific dataset, often referred to as \"ml-100k,\" contains 100,000 ratings from 943 users on 1,682 movies. The data was collected through the MovieLens website during the seven-month period from September 19th, 1997 to April 22nd, 1998.\n",
        "\n",
        "- **Data Structure**: The dataset includes user ratings that range from 1 to 5. Additionally, it provides demographic information about the users (age, gender, occupation, etc.) and details about the movies (titles, genres).\n",
        "\n",
        "- **Usage**: It's a standard dataset used for implementing and testing recommender systems. Its size is manageable, making it a popular choice for educational purposes and for initial experimentation with recommendation algorithms.\n",
        "\n",
        "- **Significance**: The diversity in the dataset, both in terms of users and movie genres, provides a rich ground for analyzing different recommendation strategies, testing algorithms like SVD, and understanding user preferences and behavioral patterns.\n",
        "\n",
        "This dataset is an excellent starting point for anyone looking to delve into the world of recommender systems and practice with real-world data.\n",
        "\n",
        "\n",
        "Now, we will write some code to understand and explore the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuT-QnvyKoWC",
        "outputId": "a54f7181-1902-44be-8b9b-0144dfa1e0b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (1.13.1)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2505160 sha256=0cf026b9b8b09c49d6c211915b32b25158ace8deb044e2d3c3c5035880aac107\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "#Run this only once, you can comment out this part of the code after.\n",
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty8MyZxKKfIl"
      },
      "outputs": [],
      "source": [
        "#Importing necessary modules for this project\n",
        "import pandas as pd\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGZBl3OnKUU8",
        "outputId": "16661ebe-3317-404c-9099-b8ccd05f620f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (1.1.4)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "#Installing the dataset from pandas, run this only once, you can comment out this part of the code after.\n",
        "!pip install pandas scikit-surprise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukvxW2AgTjdt"
      },
      "source": [
        "### How do the predictions work?\n",
        "\n",
        "1. **Model Training**:\n",
        "   - The SVD algorithm is first trained on a portion of the dataset, which includes user ratings for various movies.\n",
        "   - During training, the model learns to associate certain patterns and characteristics of users and movies with specific rating behaviors.\n",
        "\n",
        "2. **Latent Features Extraction**:\n",
        "   - SVD decomposes the rating matrix into matrices representing latent features of users and movies.\n",
        "   - These latent features capture underlying aspects that affect rating behavior but are not explicitly available in the data (like user preferences or movie characteristics).\n",
        "\n",
        "3. **Making Predictions**:\n",
        "   - Once the model is trained, it can predict ratings for user-movie pairs where the actual rating is unknown.\n",
        "   - The prediction is essentially a dot product of the latent features of the user and the movie. It represents the estimated preference of the user for that particular movie based on the learned patterns.\n",
        "\n",
        "4. **Example of a Prediction**:\n",
        "   - Suppose we want to predict how user `U` would rate movie `M`.\n",
        "   - The model uses the latent features it has learned for user `U` and movie `M` to compute a predicted rating.\n",
        "   - This prediction is a numerical value, typically on the same scale as the original ratings (e.g., 1 to 5).\n",
        "\n",
        "5. **Application**:\n",
        "   - These predictions are used to recommend movies to users.\n",
        "   - For example, the system can recommend movies that have the highest predicted ratings for a particular user.\n",
        "\n",
        "6. **Handling New Users or Movies (Cold Start Problem)**:\n",
        "   - One challenge is predicting ratings for new users or movies that have little to no rating history. This is known as the cold start problem.\n",
        "   - Solutions might involve using content-based approaches or hybrid models that don't rely solely on historical rating data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNnS2A8HKcgn",
        "outputId": "b63a7d35-a0dd-4e05-f024-6aa8c39e7024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "  user item  rating  timestamp\n",
            "0  196  242     3.0  881250949\n",
            "1  186  302     3.0  891717742\n",
            "2   22  377     1.0  878887116\n",
            "3  244   51     2.0  880606923\n",
            "4  166  346     1.0  886397596\n"
          ]
        }
      ],
      "source": [
        "data = Dataset.load_builtin('ml-100k')\n",
        "df = pd.DataFrame(data.raw_ratings, columns=[\"user\", \"item\", \"rating\", \"timestamp\"])\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU2Tw5HgNLVR"
      },
      "source": [
        "We see the following columns:\n",
        "\n",
        "* **User ID**: A unique identifier for the user who provided the rating.\n",
        "\n",
        "* **Item ID (Movie ID)**: A unique identifier for the movie that was rated.\n",
        "\n",
        "* **Rating:** The rating given to the movie by the user. In the MovieLens 100k dataset, these ratings are typically on a scale of 1 to 5.\n",
        "\n",
        "* **Timestamp:** The time at which the rating was provided. The timestamp is usually in Unix time format, which counts seconds since the Unix epoch (January 1, 1970).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9_ntUWFALcZw",
        "outputId": "85e81f90-a40a-40d6-904e-938aee73380e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35354.245317453555,\n        \"min\": 1.0,\n        \"max\": 100000.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          100000.0,\n          3.52986,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d331e65c-9ef5-47b7-9ae1-4b6743c49038\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.529860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.125674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d331e65c-9ef5-47b7-9ae1-4b6743c49038')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d331e65c-9ef5-47b7-9ae1-4b6743c49038 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d331e65c-9ef5-47b7-9ae1-4b6743c49038');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-00b94310-5fe2-42f5-9337-64dda29f2423\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00b94310-5fe2-42f5-9337-64dda29f2423')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-00b94310-5fe2-42f5-9337-64dda29f2423 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "              rating\n",
              "count  100000.000000\n",
              "mean        3.529860\n",
              "std         1.125674\n",
              "min         1.000000\n",
              "25%         3.000000\n",
              "50%         4.000000\n",
              "75%         4.000000\n",
              "max         5.000000"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TODO - Describe the statistics of this dataset.\n",
        "# Hint: Use the describe() function\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJoxe-JwMCKf"
      },
      "source": [
        "Now, we will do some data preprocessing.\n",
        "\n",
        "This will include:\n",
        "*   Checking for missing values\n",
        "*   Converting timestamps to a readable format\n",
        "*   Splitting the data into testing and training subsets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ_yvaO3LdgO",
        "outputId": "1146f46a-f036-48e8-b6ee-ec8972997300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user         0\n",
            "item         0\n",
            "rating       0\n",
            "timestamp    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgtjvngqMb0i"
      },
      "source": [
        "We see that there are no missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k2Jp5r3MgGZ",
        "outputId": "32053a21-40e2-47b7-c8e4-47fed4cb404e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-3f490c05cc3e>:2: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
            "  df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  user item  rating           timestamp\n",
            "0  196  242     3.0 1997-12-04 15:55:49\n",
            "1  186  302     3.0 1998-04-04 19:22:22\n",
            "2   22  377     1.0 1997-11-07 07:18:36\n",
            "3  244   51     2.0 1997-11-27 05:02:03\n",
            "4  166  346     1.0 1998-02-02 05:33:16\n"
          ]
        }
      ],
      "source": [
        "# Convert timestamp to a readable format\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF7oNwlFMnZf",
        "outputId": "d567e13d-59ec-48fc-f393-94d502151fdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of users: 943\n",
            "Number of items: 1652\n",
            "[('368', '551', 4.0), ('555', '762', 4.0), ('69', '742', 3.0), ('586', '431', 3.0), ('435', '455', 3.0)]\n"
          ]
        }
      ],
      "source": [
        "# Split the data into a training set and a test set\n",
        "trainset, testset = train_test_split(data, test_size=0.20)\n",
        "\n",
        "# Display the number of users and items in the training set\n",
        "print(f\"Number of users: {trainset.n_users}\")\n",
        "print(f\"Number of items: {trainset.n_items}\")\n",
        "\n",
        "# Display the first few elements of the test set\n",
        "print(testset[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl1g19D-MfmM"
      },
      "source": [
        "### Hyperparameter Tuning in SVD\n",
        "Hyperparameter tuning is a critical step in optimizing the performance of an SVD model. The goal is to find the best combination of parameters that results in the most accurate predictions or lowest error rates.\n",
        "\n",
        "#### Hyperparameters we will be tuning in this project\n",
        "\n",
        "1. **`n_factors`**:\n",
        "   - Represents the number of latent factors (or features) to extract from the dataset.\n",
        "   - The values `[50, 100, 150]` are chosen to test the model's performance with a varying number of factors. A higher number of factors can capture more complex patterns but may lead to overfitting and increased computation time.\n",
        "\n",
        "2. **`n_epochs`**:\n",
        "   - Refers to the number of iterations over the entire dataset during training.\n",
        "   - The values `[20, 30]` provide a range to evaluate whether more iterations improve model performance or lead to overtraining.\n",
        "\n",
        "3. **`lr_all`** (Learning Rate):\n",
        "   - Determines the step size at each iteration while moving toward a minimum of the loss function.\n",
        "   - The values `[0.005, 0.010]` are chosen to test how fast the model learns. A smaller learning rate may lead to more precise convergence but requires more epochs.\n",
        "\n",
        "4. **`reg_all`** (Regularization Term):\n",
        "   - Helps prevent overfitting by penalizing larger model parameters.\n",
        "   - The values `[0.02, 0.1]` offer a range to assess the impact of regularization on model performance. Higher regularization can reduce overfitting but may lead to underfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt6AeZAzOmrY"
      },
      "outputs": [],
      "source": [
        "# Define a grid of SVD hyperparameters explained above for tuning\n",
        "param_grid = {\n",
        "    'n_factors': [50, 100, 150],\n",
        "    'n_epochs': [20, 30],\n",
        "    'lr_all': [0.005, 0.010],\n",
        "    'reg_all': [0.02, 0.1]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbPGTyysRG5W"
      },
      "source": [
        "Now, we will train the model with the following parameters:\n",
        "\n",
        "1. **`SVD`**:\n",
        "   - This is the recommendation algorithm being tuned. SVD is a popular algorithm used in recommendation systems, particularly for matrix factorization.\n",
        "\n",
        "2. **`param_grid`**:\n",
        "   - This is a dictionary where keys are hyperparameter names, and values are lists of parameter settings to try as values. It defines the grid of parameters that will be tested.\n",
        "   - Example: If `param_grid` is `{'n_factors': [50, 100], 'lr_all': [0.005, 0.01]}`, GridSearchCV will evaluate the SVD algorithm for all combinations of `n_factors` and `lr_all` from these lists.\n",
        "\n",
        "3. **`measures=['RMSE', 'MAE']`**:\n",
        "   - These are the performance metrics used to evaluate the algorithm.\n",
        "   - `RMSE` stands for Root Mean Square Error, and `MAE` stands for Mean Absolute Error. Both are common metrics for evaluating the accuracy of prediction algorithms, with lower values indicating better performance.\n",
        "\n",
        "4. **`cv=3`**:\n",
        "   - This specifies the number of folds for cross-validation.\n",
        "   - In this context, `cv=3` means that a 3-fold cross-validation will be used. The dataset will be split into three parts: in each iteration, two parts will be used for training, and one part will be used for testing. This process repeats three times, each time with a different part used for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ys3MuGk5Qph4"
      },
      "outputs": [],
      "source": [
        "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV\n",
        "from surprise import SVD, Dataset, Reader, accuracy\n",
        "\n",
        "# Perform grid search with cross-validation to find the best hyperparameters for our model\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['RMSE', 'MAE'], cv=3)\n",
        "gs.fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J85rTs0wQpYT",
        "outputId": "a8bdb010-8dae-4c61-a4a4-6256885fac7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE: 0.9213237576122633\n",
            "Best parameters: {'n_factors': 100, 'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.1}\n"
          ]
        }
      ],
      "source": [
        "# Best score and parameters\n",
        "print(f\"Best RMSE: {gs.best_score['rmse']}\")\n",
        "print(f\"Best parameters: {gs.best_params['rmse']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JVCuCpr0RRMe"
      },
      "outputs": [],
      "source": [
        "# TODO - Use the best model. Use best_estimator function on gs\n",
        "algo = gs.best_estimator['rmse']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "N_rMgmt3SyGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da0cddb-2471-45a6-b57c-f19a09f21e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9088\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.908772078826"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# TODO - Train and test split. Make sure test_size is 0.25\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "# TODO - Fit the trainset to train the model\n",
        "algo.fit(trainset)\n",
        "# TODO - Make predictions on the testset\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# TODO - Calculate and print RMSE on the predictions made\n",
        "accuracy.rmse(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Qn7yRR-aRXL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d2d6f2-9913-4dd2-b38e-8b1688a961b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user 196 and item 302: 4.09794347716003\n"
          ]
        }
      ],
      "source": [
        "#Predict rating for a user and item\n",
        "user_id = '196'  # replace with a specific user ID\n",
        "item_id = '302'  # replace with a specific item (movie) ID\n",
        "predicted_rating = algo.predict(user_id, item_id)\n",
        "print(f\"Predicted rating for user {user_id} and item {item_id}: {predicted_rating.est}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TD1GVZ3FpxdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178fa531-b148-4cf1-c9e0-157f24842515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction 0: User 727 and item 384 has true rating 2.0, and the predicted rating is 2.818410345305166\n",
            "Prediction 1: User 176 and item 948 has true rating 4.0, and the predicted rating is 2.3462237308058325\n",
            "Prediction 2: User 405 and item 1572 has true rating 1.0, and the predicted rating is 2.288857737877792\n",
            "Prediction 3: User 305 and item 690 has true rating 4.0, and the predicted rating is 2.9195466963384615\n",
            "Prediction 4: User 522 and item 23 has true rating 5.0, and the predicted rating is 4.53188208519877\n",
            "Prediction 5: User 215 and item 313 has true rating 5.0, and the predicted rating is 4.067617191224672\n",
            "Prediction 6: User 508 and item 1153 has true rating 4.0, and the predicted rating is 3.354735282628489\n",
            "Prediction 7: User 279 and item 372 has true rating 4.0, and the predicted rating is 3.370148293317401\n",
            "Prediction 8: User 648 and item 204 has true rating 5.0, and the predicted rating is 4.08141892052482\n",
            "Prediction 9: User 296 and item 628 has true rating 5.0, and the predicted rating is 3.853607833754389\n"
          ]
        }
      ],
      "source": [
        "# To inspect the predictions in detail, let's print the first 10 predictions made by the model\n",
        "for idx, prediction in enumerate(predictions[:10]):\n",
        "    print(f'Prediction {idx}: User {prediction.uid} and item {prediction.iid} has true rating {prediction.r_ui}, and the predicted rating is {prediction.est}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idnQfHixB0HB"
      },
      "source": [
        "####Rounding Numbers\n",
        "Rounding values is a technique used to simplify numbers, but its appropriateness depends on the context:\n",
        "\n",
        "**When to Round**\n",
        "1. **Simplification**: For estimations.\n",
        "2. **Reporting**: When exact figures aren't necessary (e.g., in everyday language).\n",
        "3. **Data Analysis**: To focus on significant trends by ignoring minor variations.\n",
        "4. **Financial Transactions**: Rounding to the smallest currency unit.\n",
        "5. **Display Purposes**: For clarity in graphs or tables.\n",
        "\n",
        "**When NOT to Round**\n",
        "1. **Intermediate Calculations**: Early rounding can lead to significant final errors.\n",
        "2. **Legal/Regulatory Documents**: Require exact figures.\n",
        "3. **Scientific/Engineering Work**: Precision is crucial.\n",
        "4. **Critical Calculations**: In health, safety, or finance, precision is essential.\n",
        "\n",
        "To summarize,\n",
        "- Rounding depends on the purpose and context of the calculation.\n",
        "- It is useful for simplification and clarity but should be avoided when precision is critical.\n",
        "- We must be aware of potential cumulative errors in sequential calculations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TW56IrZLYej"
      },
      "source": [
        "Let us round the values of the predictions so that it falls within the rating categories of [1.0, 2.0, 3.0, 4.0, 5.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qoKsEX-TLYEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b128618-c3db-4435-cc86-958e40beabaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction 0: User 727 and item 384 has true rating 2.0, and the predicted rating is 3\n",
            "Prediction 1: User 176 and item 948 has true rating 4.0, and the predicted rating is 2\n",
            "Prediction 2: User 405 and item 1572 has true rating 1.0, and the predicted rating is 2\n",
            "Prediction 3: User 305 and item 690 has true rating 4.0, and the predicted rating is 3\n",
            "Prediction 4: User 522 and item 23 has true rating 5.0, and the predicted rating is 5\n",
            "Prediction 5: User 215 and item 313 has true rating 5.0, and the predicted rating is 4\n",
            "Prediction 6: User 508 and item 1153 has true rating 4.0, and the predicted rating is 3\n",
            "Prediction 7: User 279 and item 372 has true rating 4.0, and the predicted rating is 3\n",
            "Prediction 8: User 648 and item 204 has true rating 5.0, and the predicted rating is 4\n",
            "Prediction 9: User 296 and item 628 has true rating 5.0, and the predicted rating is 4\n"
          ]
        }
      ],
      "source": [
        "#TODO - Round the prediction.est variable being printed. Use python's default rounding function to achieve this\n",
        "import math # Importing the math module\n",
        "\n",
        "for idx, prediction in enumerate(predictions[:10]):\n",
        "    temp = math.ceil(int(prediction.est)) # Using math.ceil to round up\n",
        "    print(f'Prediction {idx}: User {prediction.uid} and item {prediction.iid} has true rating {prediction.r_ui}, and the predicted rating is {round(prediction.est)}') # Applying rounding and printing the prediction\n",
        "\n",
        "# for idx, prediction in enumerate(predictions[:10]):\n",
        "#     temp = math.ceil(int(prediction.est))\n",
        "#     print(f'Prediction {idx}: User {prediction.uid} and item {prediction.iid} has true rating {prediction.r_ui}, and the predicted rating is {______(prediction.est)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT8Rpdt4ZPeA"
      },
      "source": [
        "<h3 align = 'center' >\n",
        "Thank you for completing the project!\n",
        "</h3>\n",
        "\n",
        "Please submit all materials to the NSDC HQ team at nsdc@nebigdatahub.org in order to receive a virtual certificate of completion. Do reach out to us if you have any questions or concerns. We are here to help you learn and grow.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}